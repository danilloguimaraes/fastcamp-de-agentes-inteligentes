{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7Yw84kvZ1NHc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "7Yw84kvZ1NHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mHZJ01yay23x"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "llm_api_key = userdata.get('grok_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWi7osWVzuxY",
        "outputId": "b5ef6471-c994-488c-caff-efa425268653"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key = llm_api_key,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8XZMpQa0AN8",
        "outputId": "82701481-4602-4d36-a027-071986d63ac3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are revolutionizing the field of natural language processing (NLP) and have numerous applications across various industries. The importance of fast language models can be understood from several perspectives:\n",
            "\n",
            "1. **Efficient Processing**: Fast language models can process large volumes of text data quickly, which is essential for applications that require real-time processing, such as language translation, sentiment analysis, and chatbots. This enables businesses to respond promptly to customer inquiries, improving customer experience and reducing response times.\n",
            "2. **Scalability**: Fast language models can handle massive amounts of data, making them ideal for large-scale applications, such as text analysis, information retrieval, and language generation. This scalability enables organizations to analyze vast amounts of data, gain insights, and make informed decisions.\n",
            "3. **Real-time Applications**: Fast language models are crucial for real-time applications, such as:\n",
            "\t* Live language translation\n",
            "\t* Real-time sentiment analysis\n",
            "\t* Chatbots and virtual assistants\n",
            "\t* Speech recognition and transcription\n",
            "\t* News article summarization\n",
            "4. **Improved User Experience**: Fast language models can provide instant responses to user queries, enhancing the overall user experience. This is particularly important for applications that require quick turnaround times, such as customer service, technical support, and language learning platforms.\n",
            "5. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by:\n",
            "\t* Responding quickly to customer inquiries\n",
            "\t* Analyzing large amounts of data to gain insights\n",
            "\t* Developing innovative products and services\n",
            "\t* Improving operational efficiency\n",
            "6. **Reduced Latency**: Fast language models minimize latency, which is critical for applications that require immediate responses, such as:\n",
            "\t* Emergency services (e.g., 911 dispatch)\n",
            "\t* Financial transactions (e.g., stock trading)\n",
            "\t* Healthcare (e.g., medical diagnosis)\n",
            "7. **Cost Savings**: Fast language models can reduce the computational resources required for processing text data, leading to cost savings on infrastructure, energy consumption, and maintenance.\n",
            "8. **Advancements in AI Research**: Fast language models are essential for advancing AI research, as they enable researchers to:\n",
            "\t* Explore new NLP tasks and applications\n",
            "\t* Develop more sophisticated language models\n",
            "\t* Improve the accuracy and efficiency of language models\n",
            "9. **Accessibility**: Fast language models can make language processing more accessible to a broader audience, including:\n",
            "\t* Language learners\n",
            "\t* People with disabilities\n",
            "\t* Underserved communities\n",
            "10. **Future-Proofing**: As the amount of text data continues to grow, fast language models will become increasingly important for processing and analyzing this data efficiently. By adopting fast language models, organizations can future-proof their applications and stay ahead of the curve.\n",
            "\n",
            "In summary, fast language models are crucial for efficient processing, scalability, real-time applications, improved user experience, competitive advantage, reduced latency, cost savings, advancements in AI research, accessibility, and future-proofing. As the demand for NLP applications continues to grow, the importance of fast language models will only continue to increase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "BVlTe09G1USe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "\n",
        "  def __init__(self, client, system):\n",
        "    self.client = client\n",
        "    self.system = system\n",
        "    self.messages = []\n",
        "    if self.system is not None:\n",
        "      self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
        "\n",
        "\n",
        "  def __call__(self, message = \"\"):\n",
        "    if message is not None:\n",
        "      self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    result = self.execute()\n",
        "\n",
        "    self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "    return result\n",
        "\n",
        "\n",
        "  def execute(self):\n",
        "    completion = self.client.chat.completions.create(\n",
        "      messages=self.messages,\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "RTEuUtbD1YSL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer.\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your goal is to act as a cashier for a Pizza place.\n",
        "Rules:\n",
        "1. You must always retrieve the current menu prices before calculating.\n",
        "2. If the customer eats at the restaurant (dine-in), you MUST add a 10% service fee to the total.\n",
        "3. If the order is for takeout/delivery, there is NO service fee.\n",
        "4. Final Answer must state the items ordered and the final total price.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "get_menu:\n",
        "e.g. get_menu\n",
        "Returns a JSON object containing the available pizzas and sodas with their respective prices.\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 12 + 3\n",
        "Runs a calculation and returns the number. Use Python syntax.\n",
        "\n",
        "Example session 1:\n",
        "\n",
        "Question: I want one Pepperoni pizza and a Coke to go.\n",
        "Thought: I need to check the prices for Pepperoni and Coke.\n",
        "Action: get_menu\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: {\"pizzas\": {\"Pepperoni\": 15.00, \"Cheese\": 12.00}, \"sodas\": {\"Coke\": 3.00, \"Sprite\": 3.00}}\n",
        "\n",
        "Thought: Pepperoni is 15.00. Coke is 3.00. The customer said \"to go\", so there is no service fee. I need to sum the prices.\n",
        "Action: calculate: 15 + 3\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: 18.0\n",
        "\n",
        "Thought: The calculation is complete. I have the final total.\n",
        "Answer: You ordered a Pepperoni pizza and a Coke. The total is $18.00.\n",
        "\n",
        "Example session 2:\n",
        "\n",
        "Question: I'll have a Cheese pizza and a Sprite. I'm eating here.\n",
        "Thought: I need to check prices.\n",
        "Action: get_menu\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: {\"pizzas\": {\"Pepperoni\": 15.00, \"Cheese\": 12.00}, \"sodas\": {\"Coke\": 3.00, \"Sprite\": 3.00}}\n",
        "\n",
        "Thought: Cheese is 12.00. Sprite is 3.00. The customer is \"eating here\", so I must add 10% to the total. Calculation is (12 + 3) * 1.10.\n",
        "Action: calculate: (12 + 3) * 1.10\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: 16.5\n",
        "\n",
        "Thought: The total includes the service fee.\n",
        "Answer: You ordered a Cheese pizza and a Sprite for dine-in. The total is $16.50.\n",
        "\n",
        "Now it's your turn:\n",
        "\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "lhWp2Iqi3pbj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tools\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "def get_menu():\n",
        "    menu_data = {\n",
        "        \"pizzas\": {\n",
        "            \"Pepperoni\": 15.00,\n",
        "            \"Cheese\": 12.00\n",
        "        },\n",
        "        \"sodas\": {\n",
        "            \"Coke\": 3.00,\n",
        "            \"Sprite\": 3.00\n",
        "        }\n",
        "    }\n",
        "    return json.dumps(menu_data)\n",
        "\n",
        "\n",
        "def calculate(expression):\n",
        "    try:\n",
        "        expression = expression.strip()\n",
        "        allowed_names = {\"__builtins__\": None}\n",
        "        result = eval(expression, allowed_names)\n",
        "\n",
        "        return str(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "Wx4-JHQa6hKu"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def loop(max_iterations=10, query: str = \"\"):\n",
        "    agent = Agent(client=client, system=system_prompt)\n",
        "\n",
        "    available_tools = {\n",
        "        \"get_menu\": get_menu,\n",
        "        \"calculate\": calculate\n",
        "    }\n",
        "\n",
        "    next_prompt = query\n",
        "    i = 0\n",
        "\n",
        "    while i < max_iterations:\n",
        "        i += 1\n",
        "        result = agent(next_prompt)\n",
        "        print(f\"--- Iteração {i} ---\")\n",
        "        print(result)\n",
        "\n",
        "        if \"PAUSE\" in result and \"Action\" in result:\n",
        "            # REGRA REGEX:\n",
        "            # 1. ([a-z_]+) -> Nome da ferramenta\n",
        "            # 2. (?::\\s*(.+))? -> Opcional. Procura ':' seguido de espaço e o argumento\n",
        "            match = re.search(r\"Action: ([a-z_]+)(?::\\s*(.+))?\", result, re.IGNORECASE)\n",
        "\n",
        "            if match:\n",
        "                chosen_tool = match.group(1)\n",
        "                arg = match.group(2)\n",
        "\n",
        "                if chosen_tool in available_tools:\n",
        "\n",
        "                    if chosen_tool == \"get_menu\":\n",
        "                      result_tool = get_menu()\n",
        "\n",
        "                      # Ou chamando por available_tools\n",
        "                      # result_tool = available_tools[chosen_tool]()\n",
        "\n",
        "                    else:\n",
        "                      result_tool = calculate(arg)\n",
        "\n",
        "                      # Ou chamando por available_tools\n",
        "                      # result_tool = available_tools[chosen_tool](arg)\n",
        "\n",
        "                    next_prompt = f\"Observation: {result_tool}\"\n",
        "                else:\n",
        "                    next_prompt = \"Observation: Tool not found\"\n",
        "\n",
        "                print(next_prompt)\n",
        "                continue\n",
        "            else:\n",
        "                print(\"Error: Could not parse Action from agent response.\")\n",
        "                break\n",
        "\n",
        "        if \"Answer\" in result:\n",
        "            break\n",
        "\n",
        "# Rodando\n",
        "loop(query=\"I want a Cheese pizza and a Coke. I will be eating at the restaurant.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjHM0GNqlMwa",
        "outputId": "0343c1cb-924e-40cc-a651-46544f435883"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iteração 1 ---\n",
            "Thought: I need to check the current menu prices for Cheese pizza and Coke before calculating the total. Since the customer is eating at the restaurant, I must also consider adding a 10% service fee to the total.\n",
            "\n",
            "Action: get_menu\n",
            "PAUSE\n",
            "Observation: {\"pizzas\": {\"Pepperoni\": 15.0, \"Cheese\": 12.0}, \"sodas\": {\"Coke\": 3.0, \"Sprite\": 3.0}}\n",
            "--- Iteração 2 ---\n",
            "Thought: The price of a Cheese pizza is 12.0 and the price of a Coke is 3.0. Since the customer is eating at the restaurant, I need to calculate the total with a 10% service fee. The calculation will be (12 + 3) * 1.10.\n",
            "\n",
            "Action: calculate: (12 + 3) * 1.10\n",
            "PAUSE\n",
            "Observation: 16.5\n",
            "--- Iteração 3 ---\n",
            "Thought: The calculation is complete, and the total price for a Cheese pizza and a Coke, including the 10% service fee for dining in, is 16.5.\n",
            "\n",
            "Answer: You ordered a Cheese pizza and a Coke for dine-in. The total is $16.50.\n"
          ]
        }
      ]
    }
  ]
}